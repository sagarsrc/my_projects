{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-cfae22b8009d>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/sag/anaconda3/envs/mlai/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/sag/anaconda3/envs/mlai/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sag/anaconda3/envs/mlai/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sag/anaconda3/envs/mlai/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sag/anaconda3/envs/mlai/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)\n",
    "\n",
    "# insights of dataset\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for input images\n",
    "\"\"\"\n",
    "Why reshape to -1? -1 is a placeholder that says \n",
    "\"adjust as necessary to match the size needed for the full tensor.\" \n",
    "It's a way of making the code be independent of the input batch size, \n",
    "so that you can change your pipeline and not have to adjust the batch size \n",
    "everywhere in the code.\n",
    "\"\"\"\n",
    "x = tf.placeholder(tf.float32, [None,28*28], name='X')\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "# placeholder for true y labels associated with images\n",
    "y_true = tf.placeholder(tf.float32, [None, 10], name='Y')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolutional layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights shape = [height_of_filter, width_of_filter, no_ip_channels, depth_of_layer]\n",
    "# here depth_of_layer is no. of feature maps\n",
    "# using 5X5 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 28, 28, 6) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,6]))\n",
    "b_conv1 = tf.Variable(tf.constant(0.01, shape=[6]))\n",
    "\n",
    "conv1 = tf.nn.conv2d(x_image, w_conv1, strides=[1,1,1,1], padding='SAME')+ b_conv1\n",
    "# note that output of conv1 is 6 28X28 images\n",
    "conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relu layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 28, 28, 6) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu1 = tf.nn.relu(conv1)\n",
    "relu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pooling layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 28, 28, 6) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel size [no_of_kernels, kernel_height, kernel_width, no_of_channels]\n",
    "pool1 = tf.nn.max_pool(value=relu1, ksize=[1,2,2,1], strides=[1,1,1,1], padding='SAME')\n",
    "pool1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolutional layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=(?, 28, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <tf.Tensor 'Relu_2:0' shape=(?, 28, 28, 6) dtype=float32>\n",
    "# we have 6 feature maps of 28 by 28\n",
    "# notice : w_conv2 = tf.Variable(tf.truncated_normal(shape=[2,2,6,32]))\n",
    "# now we convolute using 2 by 2 filter and get 32 feature maps\n",
    "\n",
    "w_conv2 = tf.Variable(tf.truncated_normal(shape=[2,2,6,32]))\n",
    "b_conv2 = tf.Variable(tf.constant(0.05, shape=[32]))\n",
    "\n",
    "conv2 = tf.nn.conv2d(pool1, w_conv2, strides=[1,1,1,1], padding='SAME')+ b_conv2\n",
    "# note that output of conv1 is 6 28X28 images\n",
    "conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relu layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 28, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu2 = tf.nn.relu(conv2)\n",
    "relu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pooling layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_1:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel size [no_of_kernels, kernel_height, kernel_width, no_of_channels]\n",
    "# notice strides=[1,2,2,1]\n",
    "# after sliding 2 cells at a time dimensionality reduction can be seen\n",
    "# pool2 <tf.Tensor 'MaxPool_2:0' shape=(?, 14, 14, 32) dtype=float32>\n",
    "pool2 = tf.nn.max_pool(value=relu2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "pool2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fully connected network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 6272) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fcn1 fully connected network\n",
    "# now we flatten all the feature maps and\n",
    "# send it to fully connected network\n",
    "\n",
    "fcn_mat1 = tf.reshape(pool2,shape=[-1,14*14*32])\n",
    "fcn_mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=(?, 256) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights and biases for fcn1\n",
    "w_fcn1 = tf.Variable(tf.truncated_normal(shape=[14*14*32,256],stddev=0.5))\n",
    "b_fcn1 = tf.Variable(tf.constant(value=0.3 , shape=[256]))\n",
    "\n",
    "# mat mul operation\n",
    "mat_mul_fcn1 = tf.matmul(fcn_mat1,w_fcn1) + b_fcn1\n",
    "mat_mul_fcn1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relu layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 256) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu3 = tf.nn.relu(mat_mul_fcn1)\n",
    "relu3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fully connected network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights and biases for fcn1\n",
    "w_fcn2 = tf.Variable(tf.truncated_normal(shape=[256,10],stddev=0.5))\n",
    "b_fcn2 = tf.Variable(tf.constant(value=0.05 , shape=[10]))\n",
    "\n",
    "# mat mul operation\n",
    "mat_mul_fcn2 = tf.matmul(relu3,w_fcn2) + b_fcn2\n",
    "mat_mul_fcn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax will generate probabilities \n",
    "# or scores of each digit we need to choose max probability\n",
    "# axis = 1 meaning in columns\n",
    "\n",
    "y_pred = tf.nn.softmax(mat_mul_fcn2)\n",
    "y_pred_cls = tf.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=mat_mul_fcn2, labels=y_true)\n",
    "cost =tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimiser and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using adam optimiser\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "# this is to convert integer to float32 for accuracy check\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed : Time usage 48 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.2823999995365739\n",
      "\t- Validation Accuracy:\t0.4519999921321869\n",
      "\t- Test Accuracy:\t0.4000000059604645\n",
      "Epoch 2 completed : Time usage 42 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.5526000007987022\n",
      "\t- Validation Accuracy:\t0.6489999890327454\n",
      "\t- Test Accuracy:\t0.699999988079071\n",
      "Epoch 3 completed : Time usage 40 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.6924000012874604\n",
      "\t- Validation Accuracy:\t0.7305999994277954\n",
      "\t- Test Accuracy:\t0.800000011920929\n",
      "Epoch 4 completed : Time usage 38 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.7519999986886978\n",
      "\t- Validation Accuracy:\t0.7764000296592712\n",
      "\t- Test Accuracy:\t0.8100000023841858\n",
      "Epoch 5 completed : Time usage 40 seconds\n",
      "\tAccuracy:\n",
      "\t- Training Accuracy:\t0.7870999991893768\n",
      "\t- Validation Accuracy:\t0.8090000152587891\n",
      "\t- Test Accuracy:\t0.75\n",
      "Total time required to train:  210.71363878250122\n"
     ]
    }
   ],
   "source": [
    "train_acc_array = []\n",
    "valid_acc_array = []\n",
    "test_acc_array = []\n",
    "pred_results = []\n",
    "\n",
    "# initialize all global variables\n",
    "sess.run(tf.initializers.global_variables())\n",
    "total_time_t0 = time.time()\n",
    "\n",
    "for epochs in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_accuracy = 0\n",
    "\n",
    "    # Training-set consists: 55000\n",
    "    # Using only 50 epochs\n",
    "    # Training only 10 batches per epoch\n",
    "    # Therefore total of 50*10 iterations\n",
    "    for batch in range(100):\n",
    "\n",
    "        # get batch of images and labels\n",
    "        x_batch, y_true_batch = data.train.next_batch(batch_size)\n",
    "\n",
    "        # set feed_dict_train\n",
    "        feed_dict_train = {x:x_batch, y_true:y_true_batch}\n",
    "\n",
    "        # feed dictionary into optimiser for training\n",
    "        sess.run(optimizer,feed_dict=feed_dict_train)\n",
    "\n",
    "        # Calculate the cumulative accuracy on the batch of training data\n",
    "        train_accuracy += sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "        # print(\"*** Train_accuracy_batch\",train_accuracy)\n",
    "\n",
    "\n",
    "    # get validation sets\n",
    "    v_img, v_labels = data.validation.next_batch(100)\n",
    "    # feed validation set\n",
    "    vali_accuracy = sess.run(accuracy, feed_dict={x:data.validation.images, y_true:data.validation.labels})\n",
    "\n",
    "    # get test sets\n",
    "    tst_imgs, tst_labels = data.test.next_batch(100)\n",
    "    # check over test set\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={x:tst_imgs, y_true:tst_labels})\n",
    "    \n",
    "    # printing test images and their labels\n",
    "    pred_batch_x, pred_batch_y = data.test.next_batch(5)\n",
    "    pred_results.append([pred_batch_x,sess.run(y_pred,feed_dict={x:pred_batch_x})])\n",
    "\n",
    "    # average train accuracy\n",
    "    # train_accuracy /= int(len(data.train.labels)/batch_size)\n",
    "    train_accuracy /= 100\n",
    "    \n",
    "    # appending in arrays for plotting\n",
    "    train_acc_array.append(train_accuracy)\n",
    "    valid_acc_array.append(vali_accuracy)\n",
    "    test_acc_array.append(test_accuracy)\n",
    "    \n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Epoch \"+str(epochs+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n",
    "    print(\"\\tAccuracy:\")\n",
    "    print (\"\\t- Training Accuracy:\\t{}\".format(train_accuracy))\n",
    "    print (\"\\t- Validation Accuracy:\\t{}\".format(vali_accuracy))\n",
    "    print (\"\\t- Test Accuracy:\\t{}\".format(test_accuracy))\n",
    "\n",
    "total_time_tn = time.time()\n",
    "print(\"Total time required to train: \",total_time_tn-total_time_t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [8.1661946e-36, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00]], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.10980393, 0.52156866,\n",
       "       0.5764706 , 0.8941177 , 0.8000001 , 0.5764706 , 0.2509804 ,\n",
       "       0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.10980393, 0.9215687 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.74509805, 0.454902  ,\n",
       "       0.19215688, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01960784, 0.43529415,\n",
       "       0.54901963, 0.54901963, 0.54901963, 0.7490196 , 0.9803922 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.95294124, 0.43921572,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07843138, 0.4039216 , 0.60784316,\n",
       "       0.93725497, 0.9960785 , 0.9960785 , 0.6313726 , 0.03529412,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.16470589, 0.5882353 ,\n",
       "       0.9803922 , 0.9960785 , 0.45098042, 0.01568628, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.13333334, 0.83921576,\n",
       "       0.9960785 , 0.8078432 , 0.01568628, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.9607844 , 0.9960785 ,\n",
       "       0.5803922 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.8117648 , 0.9960785 , 0.7411765 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.8117648 ,\n",
       "       0.9960785 , 0.7411765 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.24313727, 0.9294118 , 0.9960785 , 0.6509804 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.65882355,\n",
       "       0.9960785 , 0.91372555, 0.06666667, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5176471 , 0.97647065, 0.9960785 , 0.63529414,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0509804 , 0.3921569 , 0.97647065,\n",
       "       0.9960785 , 0.6431373 , 0.01568628, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02745098,\n",
       "       0.5137255 , 0.9960785 , 0.9960785 , 0.6431373 , 0.03921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.23137257, 0.74509805, 0.9960785 , 0.9960785 ,\n",
       "       0.28235295, 0.01568628, 0.        , 0.        , 0.        ,\n",
       "       0.09019608, 0.5254902 , 0.20392159, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.34117648, 0.92549026,\n",
       "       1.        , 0.9450981 , 0.40784317, 0.01960784, 0.        ,\n",
       "       0.21176472, 0.30588236, 0.68235296, 0.9450981 , 0.8000001 ,\n",
       "       0.23137257, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.6117647 , 0.9960785 , 0.9960785 , 0.8000001 , 0.28627452,\n",
       "       0.32156864, 0.62352943, 0.8313726 , 0.9686275 , 0.9960785 ,\n",
       "       0.72156864, 0.2392157 , 0.07450981, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.15294118, 0.69411767, 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.59607846, 0.82745105, 0.9960785 , 0.98823535,\n",
       "       0.8705883 , 0.7058824 , 0.21960786, 0.00784314, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.59607846,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.8196079 , 0.38823533, 0.27058825, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.16078432, 0.7058824 , 0.9803922 ,\n",
       "       0.57254905, 0.57254905, 0.3647059 , 0.05490196, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[4][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "5\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].imshow(np.reshape(pred_results[4][0][0],(28,28)),cmap='gray');print(np.argmax(pred_results[4][1][0]))\n",
    "axarr[0,1].imshow(np.reshape(pred_results[4][0][1],(28,28)),cmap='gray');print(np.argmax(pred_results[4][1][1]))\n",
    "axarr[1,0].imshow(np.reshape(pred_results[4][0][2],(28,28)),cmap='gray');print(np.argmax(pred_results[4][1][2]))\n",
    "axarr[1,1].imshow(np.reshape(pred_results[4][0][3],(28,28)),cmap='gray');print(np.argmax(pred_results[4][1][3]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
